<!doctype html>
<!--[if IE 7 ]>    <html lang="en-gb" class="isie ie7 oldie no-js"> <![endif]-->
<!--[if IE 8 ]>    <html lang="en-gb" class="isie ie8 oldie no-js"> <![endif]-->
<!--[if IE 9 ]>    <html lang="en-gb" class="isie ie9 no-js"> <![endif]-->
<!--[if (gt IE 9)|!(IE)]><!-->
<html lang="en-gb" class="no-js">
<!--<![endif]-->
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<!--[if lt IE 9]> 
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
    <![endif]-->
<title>Cooperative Multi-Agent Systems Decision-making and Learning: Human-Multi-Agent Cognitive Fusion</title>
<meta name="description" content="">
<meta name="author" content="WebThemez">
<!--[if lt IE 9]>
        <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
<!--[if lte IE 8]>
		<script type="text/javascript" src="http://explorercanvas.googlecode.com/svn/trunk/excanvas.js"></script>
	<![endif]-->
<link rel="shortcut icon" href="images/cog.ico">
<link rel="stylesheet" href="css/bootstrap.min.css" />
<link rel="stylesheet" type="text/css" href="css/isotope.css" media="screen" />
<link rel="stylesheet" href="js/fancybox/jquery.fancybox.css" type="text/css" media="screen" />
<link href="css/animate.css" rel="stylesheet" media="screen">
<link href="flexslider/flexslider.css" rel="stylesheet" />
<link href="js/owl-carousel/owl.carousel.css" rel="stylesheet">
<link rel="stylesheet" href="css/styles.css" />
<!-- Font Awesome -->
<link href="font/css/font-awesome.min.css" rel="stylesheet">

<style>
    table {
      border-collapse: separate;
      border-spacing: 20px 0;
    }

    td {
      padding: 5px;
    }
</style>
	
<style>
    .collapsible {
      background-color: white;
      color: maroon;
/*       color: blue; */
      cursor: pointer;
      width: 100%;
      border: none;
      text-align: left;
      outline: none;
    }

    .collapsible:hover {
      background-color: rgb(240, 240, 240);
    }

    .collapsible:after {
      content: '\002B';
      color: black;
      font-weight: bold;
      float: right;
      margin-left: 5px;
      margin-right: 15px;
    }

    .left-col {
      width: 15%;
    }

    .collapsible.active::after {
      content: "\2212";
    }

    .hidden-content {
      padding: 0 5px;
      overflow: hidden;
      background-color: white;
      max-height: 0;
      line-height: 115%;
      transition: max-height 0.2s ease-out;
    }
  </style>
</head>

<body>
<header class="header">
  <div class="container">
    <nav class="navbar navbar-inverse" role="navigation">
      <div class="navbar-header">
        <button type="button" id="nav-toggle" class="navbar-toggle" data-toggle="collapse" data-target="#main-nav"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar"></span> <span class="icon-bar"></span> <span class="icon-bar"></span> </button>
        <a href="#" class="navbar-brand scroll-top logo  animated bounceInLeft"><b><i>Cooperative Multi-Agent Systems Decision-making and Learning</i></b></a> </div>
      <!--/.navbar-header-->
      <div id="main-nav" class="collapse navbar-collapse">
        <ul class="nav navbar-nav" id="mainNav">
          <li class="active" id="firstLink"><a href="#home" class="scroll-link">Home</a></li>
          <li><a href="#aboutUs" class="scroll-link">About</a></li>
	  <li><a href="#services" class="scroll-link">Speakers</a></li>
          <li><a href="#plans" class="scroll-link">Program</a></li>
          <li><a href="#work" class="scroll-link">Contributions</a></li>
          <li><a href="#team" class="scroll-link">Organizers</a></li>
          <li><a href="#contactUs" class="scroll-link">Submission</a></li>
	  <li><a href="#pastEvents" class="scroll-link">Past Events</a></li>
        </ul>
      </div>
      <!--/.navbar-collapse--> 
    </nav>
    <!--/.navbar--> 
  </div>
  <!--/.container--> 
</header>
<!--/.header-->
<div id="#top"></div>
<section id="home">
  <div class="banner-container"> 
  <!-- Slider -->
        <div id="main-slider" class="flexslider">
            <ul class="slides">
              <li>
                <img src="images/slides/0.png" alt="" />
                <div class="flex-caption">
                    <h3>Invited Speakers</h3> 
					<p>Intrinsically motivated AI agent modeling in MAS</p>  
                </div>
              </li>
		    
<!-- 	      <li>
                <img src="images/slides/3.png" alt="" />
                <div class="flex-caption">
                    <h3>Workshop On Site</h3> 
					<p>Game-theoretic approaches and Cognitive Computing in Cooperative MAS</p>  
                </div>
              </li> -->
		    
<!-- 	      <li>
                <img src="images/slides/1.png" alt="" />
                <div class="flex-caption">
                    <h3>Oral Presentations</h3> 
					<p>Multi-Aegnt Interaction</p>  
                </div>
              </li> -->
		    
<!--               <li>
                <img src="images/slides/2.png" alt="" />
                <div class="flex-caption">
                    <h3>Poster Presentations</h3> 
					<p>Multi-Agennt Coginitve Modeling and Human-Robot Cognitive Fusion</p>  
                </div>
              </li> -->
              
<!-- 	      <li>
                <img src="images/slides/4.png" alt="" />
                <div class="flex-caption">
                    <h3>Self-Adaptive MAS in Cooperation</h3> 
					<p>Efficient planning and learning adapting group members to achieve team goals</p>  
                </div>
              </li>
	      <li>
                <img src="images/slides/5.png" alt="" />
                <div class="flex-caption">
                    <h3>Innate-values-driven behaviors</h3> 
					<p>Cognitive models in swarm intelligence and robotics</p>  
                </div>
              </li> -->
            </ul>
        </div>
	<!-- end slider -->
  </div>
  <div class="container hero-text2">
  <h3>AAAI 2025 Full-Day Workshop <br /> Cooperative Multi-Agent Systems Decision-making and Learning: <br />Human-Multi-Agent Cognitive Fusion 
	  <br />Pennsylvania Convention Center, Philadelphia, PA, USA, Mar. 03, 2025
	  <br />AAAI CMASDL Workshop (#W11): <a href="https://aaai.org/conference/aaai/aaai-25/workshop-list/" target="blank">https://aaai.org/conference/aaai/aaai-25/workshop-list/</a>
	  <br />[This workshop will be held in person]
	  <br />[AAAI 2025 registration (workshop-only) is required]
  	  <br />Submission Link: <a href="https://easychair.org/conferences/?conf=aaai2025cmasdlworksh" target="blank">https://easychair.org/conferences/?conf=aaai2025cmasdlworksh</a>
	  <br />Workshop paper submission deadline: 22 November 2024, 11:59 pm Pacific Time.
	  <br />Notification to authors: 21 December 2024.
  </h3>
  </div>
</section>
	
<section id="aboutUs">
  <div class="container">
    <div class="heading text-center"> 
      <!-- Heading -->
      <h2>About</h2>
    </div>
	  <p style="font-size: 20px;">This workshop focuses on the role of decision-making and learning in human-multi-agent cooperation, viewed through the lens of cognitive modeling. 
		  AI technologies, particularly in human-robot interaction, are increasingly focused on cognitive modeling, encompassing everything from visual processing to symbolic reasoning 
		  and action recognition. These capabilities support human-agent cooperation in complex tasks. </p>
	  <p style="font-size: 20px;">
		  <img src="images/ERG.png" align="right" alt="" width="30%" hspace="" vspace="">
		  Natural agents, like humans, often make decisions based on a blend of biological, social, and cognitive motivations, as elucidated by combined motivations' model like Maslow’s Hierarchy of Needs and 
		  Alderfer’s Existence-Relatedness-Growth (ERG) theory. On the other hand, the AI agent can be regarded as a self-organizing system that also presents various needs and motivations 
		  in its evolution through decision-making and learning to adapt to different scenarios and satisfy their needs. Combined with AI agent capacity to aid decision-making, it opens up new horizons in human-multi-agent collaboration. 
		  This potential is crucially essential in the context of interactions between human agents and intelligent agents, when considering to establish stable and reliable relationships in their cooperation, 
		  particularly in adversarial and rescue mission environments. </p>
	  <p style="font-size: 20px;">This workshop will bring together researchers from multi-agent systems (MAS) and human-robot interaction (HRI) and aims to advance the field by exploring how cognitive science, 
		  mathematical modeling, statistical analysis, software simulations, and hardware demonstrations can help answer critical questions about decision-making and learning in these cooperative environments. 
		  The goal is to understand better how cognitive modeling can enhance cooperation between humans and AI agents, especially in complex, high-stakes scenarios.</p>
    <div class="row feature design">
      <div class="area1 columns right">
        <h3>Topics</h3>
        <p style="font-size: 20px;">We solicit contributions from topics including but not limited to:</p>
	<ul>
<!-- 		<li style="font-size: 18px;">MAS cognitive modeling</li> -->
		<li style="font-size: 18px;">Human-multi-agent cognitive modeling</li>
		<li style="font-size: 18px;">Human-multi-agent trust networks</li>
		<li style="font-size: 18px;">Trustworthy AI agents in Human-robot interaction</li>
		<li style="font-size: 18px;">Trust based Human-MAS decision-making and learning</li>
		<li style="font-size: 18px;">Consensus in Human-MAS collaboration</li>
<!-- 		<li style="font-size: 18px;">Human-multi-agent reinforcement learning modeling</li> -->
		<li style="font-size: 18px;">Intrinsically motivated AI agent modeling in Human-MAS</li>
		<li style="font-size: 18px;">Innate-values-driven reinforcement learning</li>
<!-- 		<li style="font-size: 18px;">MAS deep reinforcement learning</li> -->
		<li style="font-size: 18px;">Multi-Objective MAS decision-making and learning</li>
		<li style="font-size: 18px;">Adaptive learning with social rewards</li>
		<li style="font-size: 18px;">Cognitive models in swarm intelligence and robotics</li>
		<li style="font-size: 18px;">Game-theoretic approaches in MAS decision-making</li>
		<li style="font-size: 18px;">Cognitive model application in intelligent social systems</li>
	</ul>
      </div>
      <div class="area2 columns feature-media left"> 
	<div class="topic-img">
		<img src="images/thinker.png" alt="" width="100%"> 
	</div>
      </div>
    </div>

</section>
<section id="clients">
  <div id="demo" class="clients">
    <div class="container">
      <div class="heading text-center">
        <h2>Sponsors</h2>
<!-- 	<p style="font-size: 20px;">TBD </p> -->
      </div>
      <div class="row">
        <div class="col-md-12">
          <div class="customNavigation"> <a class="prev"><i class="fa fa-chevron-circle-left"></i></a> <a class="next"><i class="fa fa-chevron-circle-right"></i></a> </div>
          <div id="owl-demo" class="owl-carousel">		  
<!--             <div class="item"> <span class="helper"> <img src="images/clients/now-publishers.png" alt="client" /></span> </div> -->
		  
          </div>
        </div>
      </div>
    </div>
  </div>
</section>	

<section id="services" class="page-section colord">
  <div class="container">
    <div class="heading text-center">
      <h2 style="color: white;">Invited Speakers</h2>
    </div>
    <div class="row"> 
	    
      <!-- item -->
      <div class="col-md-3 col-sm-6 col-xs-6 text-center"> 
	<div class="team-member pDark"> 
            <!-- Image Hover Block -->
            <div class="member-img"> 
              <!-- Image  --> 
              <img class="img-responsive" src="images/ks.png" alt="" /> </div>
            <!-- Member Details -->
            <h3><a href="https://www.ri.cmu.edu/ri-faculty/katia-sycara/" target="blank">Katia Sycara</a></h3>
            <!-- Designation --> 
	    <p>Director of the Advanced Agent-Robotics Technology Lab,<br />Carnegie Mellon University</p>
        </div>
      </div>
      <!-- end: --> 

      <!-- item -->
      <div class="col-md-3 col-sm-6 col-xs-6 text-center"> 
	<div class="team-member pDark"> 
            <!-- Image Hover Block -->
            <div class="member-img"> 
              <!-- Image  --> 
              <img class="img-responsive" src="images/ps.png" alt="" /> </div>
            <!-- Member Details -->
            <h3><a href="https://www.cs.utexas.edu/~pstone/" target="blank">Peter Stone</a></h3>
            <!-- Designation --> 
	    <p>AAAI/IEEE/ACM Fellow, <br />University of Texas at Austin</p>
        </div>
      </div>
      <!-- end: --> 
      
      <!-- item -->
      <div class="col-md-3 col-sm-6 col-xs-6 text-center"> 
	<div class="team-member pDark"> 
            <!-- Image Hover Block -->
            <div class="member-img"> 
              <!-- Image  --> 
              <img class="img-responsive" src="images/bm.jpg" alt="" /> </div>
            <!-- Member Details -->
            <h3><a href="https://bmutlu.github.io/" target="blank">Bilge Mutlu</a></h3>
            <!-- Designation --> 
	    <p>Director of the People and Robots Laboratory, <br />University of Wisconsin–Madison</p>
        </div>
      </div>
      <!-- end: --> 

      <!-- item -->
      <div class="col-md-3 col-sm-6 col-xs-6 text-center"> 
	<div class="team-member pDark"> 
            <!-- Image Hover Block -->
            <div class="member-img"> 
              <!-- Image  --> 
              <img class="img-responsive" src="images/tp.png" alt="" /> </div>
            <!-- Member Details -->
            <h3><a href="https://ae.gatech.edu/directory/person/panagiotis-tsiotras" target="blank">Panagiotis Tsiotras</a></h3>
            <!-- Designation --> 
	    <p>Fellow of the AIAA, IEEE, and AAS,<br />Georgia Institute of Technology</p>
        </div>
      </div>
      <!-- end: --> 

      <!-- item -->
      <div class="col-md-3 col-sm-6 col-xs-6 text-center"> 
	<div class="team-member pDark"> 
            <!-- Image Hover Block -->
            <div class="member-img"> 
              <!-- Image  --> 
              <img class="img-responsive" src="images/sk.png" alt="" /> </div>
            <!-- Member Details -->
            <h3><a href=" " target="blank">TBD</a></h3>
            <!-- Designation --> 
<!-- 	    <p>AAAI Fellow, the Association of ACM/IEEE/AAAS <br />University of Southern California</p> -->
        </div>
      </div>
      <!-- end: -->

      <!-- item -->
      <div class="col-md-3 col-sm-6 col-xs-6 text-center"> 
	<div class="team-member pDark"> 
            <!-- Image Hover Block -->
            <div class="member-img"> 
              <!-- Image  --> 
              <img class="img-responsive" src="images/ac.png" alt="" /> </div>
            <!-- Member Details -->
            <h3><a href=" " target="blank">TBD</a></h3>
            <!-- Designation --> 
<!-- 	    <p>CIFAR Fellow and Chair,<br />Université de Montréal</p> -->
        </div>
      </div>
      <!-- end: -->

      <!-- item -->
      <div class="col-md-3 col-sm-6 col-xs-6 text-center"> 
	<div class="team-member pDark"> 
            <!-- Image Hover Block -->
            <div class="member-img"> 
              <!-- Image  --> 
              <img class="img-responsive" src="images/ac.png" alt="" /> </div>
            <!-- Member Details -->
            <h3><a href=" " target="blank">TBD</a></h3>
            <!-- Designation --> 
<!-- 	    <p>Director of Making Innovative Space Technology Lab,<br />Polytechnique Montreal</p> -->
        </div>
      </div>
      <!-- end: -->

      <!-- item -->
      <div class="col-md-3 col-sm-6 col-xs-6 text-center"> 
	<div class="team-member pDark"> 
            <div class="member-img"> 
              <img class="img-responsive" src="images/ac.png" alt="" /> </div>
            <h3><a href=" " target="blank">TBD</a></h3>
<!-- 	    <p>Director of Lab for Learning and Planning in Robotics,<br />Northeastern University</p> -->
        </div>
      </div>
      <!-- end: -->
	    
    </div>
  </div>

<!--     <div class="row dataTxt">	 -->
<!-- 						<div class="col-md-6 col-sm-6"> -->
	    
<!-- 						<div class="col-md-6">
							<h4>Workshop Video: Part 1 (9:00 am -- 12:30 pm)</h4>
							<div class="iframe_container"><iframe class="video" width="560" height="315" src="https://www.youtube.com/embed/-pVmsgo-RNU?si=4C8zLdZYwkhgirZs" 
											frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div> -->
							
<!-- 							<p style="font-size: 18px;">This workshop is part of <a href="https://aaai.org/aaai-conference/aaai-24-workshop-list/#ws13" target="blank">the Thirty-Eight AAAI Conference on Artificial Intelligence (AAAI-24)</a>.
								Virtual attendance will be available to every audience who has registered for the workshop. </p> -->
<!-- 						</div> -->
						
<!-- 						<div class="col-md-6 col-sm-6"> -->
	  
<!-- 						<div class="col-md-6">	
							<h4>Workshop Video: Part 2 (2:00 pm -- 17:30 pm)</h4>
							<div class="iframe_container"><iframe class="video" width="560" height="315" src="https://www.youtube.com/embed/OZmbGpl2ypw?si=cuj-6hez_Bm5areB" 
											frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe></div> -->
							
<!-- 							<p style="font-size: 18px;">Submission Link: <a href="https://easychair.org/conferences/?conf=aaai2024cmasdlworksh" target="blank">https://easychair.org/conferences/?conf=aaai2024cmasdlworksh</a></p>
                            				<ul class="listArrow">
								<li style="color:#0000FF; font-size: 18px;">Submission Deadline: 30 Nov. 2023</li>
								<li style="color:#0000FF; font-size: 18px;">Author Notification Date: 16 Dec. 2023</li>
								<li style="color:#0000FF; font-size: 18px;">Camera Ready Date: 15 Jan. 2024</li>
								<li style="color:#FF0000; font-size: 18px;">Workshop Date: 26 Feb. 2024</li>
							</ul> -->
<!-- 							</div> -->
						
<!-- 						<div class="col-md-4 col-sm-6">
							<h4>Publication Opportunities:</h4>
							<p style="font-size: 18px;">
								Acceptance papers will be made publicly available on the workshop website. 
								These non-archival papers and their corresponding posters will also remain available on this website after the workshop. The authors will retain copyright of their papers.
								Selected high-quality papers from the workshop will provide the opportunity to adapt or expand into a book chapter publishing in <a href="https://www.nowpublishers.com" target="blank">NowPublishers</a> according to authors' needs and agreement.
							</p>
						</div> -->
						
<!-- 					</div> -->
<!--   </div> -->
	
  <!--/.container--> 
</section>

<section id="plans" class="page-section">
  <div class="container">
    <div class="heading text-center"> 
      <!-- Heading -->
      <h2>Workshop Schedule</h2>
      <p style="font-size: 20px;">TBD </p>
    </div>

<!--     <div class="row mt-0">
        <font size="4" face="Helvetica">
          <table width="100%">
            <tbody>
              <tr>
                <td class="left-col" style="color:navy"></td> <br>
                <td style="color:maroon">All times in PST (GMT-8), Mar. 03, 2025</td>
              </tr>
              <tr>
                <td class="left-col" style="color:navy">9:00a</td> <br>
                <td style="color:navy">Welcome Remarks</td>
              </tr>
              <tr>
                <td class="left-col" style="color:navy">9:10a</td>
                <td style="color:navy">Invited Session 1</td>
              </tr>
              <tr>
                <td style="color:maroon">9:10-9:40a</td>
                <td>
                  <div class="collapsible">Maria Gini (University of Minnesota) - Topic: What would you do if you had 10, 1000, or 10000 robots?</div>
                  <div class="hidden-content">
                    <p style="margin-top:8pt; margin-bottom:7pt; text-align:justify">
                      <b>
                        <font size="">Abstract:</font>
                      </b>
                        If you had robots to do tasks, how many robots would you use? Does the answer depend on the tasks? Are the tasks independent of each other, so they can be done in parallel with no coordination,
			or must some tasks be completed before others? Do the robots need a central controller to coordinate their work, or can each robot work independently? Who will decide which robot does what task? These are
			central research questions that I will address in the talk.
                    </p>
                  </div>
                </td>
              </tr>
              <tr>
                <td style="color:maroon">9:40-10:10a</td>
                <td>
                  <div class="collapsible">Aaron Courville (Université de Montréal) - Topic: Q-value Shaping</div>
                  <div class="hidden-content">
                    <p style="margin-top:8pt; margin-bottom:7pt; text-align:justify">
                      <b>
                        <font size="">Abstract:</font>
                      </b>
                        In various real-world scenarios, interactions among agents often resemble the dynamics of general-sum games, 
		        where each agent strives to optimize its own utility. Despite the ubiquitous relevance of such settings, 
		        decentralized machine learning algorithms have struggled to find equilibria that maximize individual utility 
			while preserving social welfare. In this talk I will discuss our latest efforts in this direction by introducing Q-value Shaping, 
			a novel decentralized RL algorithm tailored to optimizing an agent's individual utility while fostering cooperation among adversaries in partially competitive environments. 
			we assume that during training, the opponent samples actions proportionally to their action-value function Q and we further assume that the agent has access to this Q function. 
			Experimental results demonstrate the effectiveness of our approach at achieving state-of-the-art performance in benchmark scenarios such as the Iterated Prisoner's Dilemma 
			and the Coin Game. We believe this method to be an important step toward training agent for practical multi-agent applications.
                    </p>
                  </div>
                </td>
              </tr>
              <tr>
                <td>10:10-10:15a</td>
                <td>Q/A and Discussion for Invited Session 1</td>
              </tr>
              <tr>
                <td style="color:green">10:15a</td>
                <td>
                  <div class="collapsible" style="color:green">Contributed Papers - Oral Presentations</div>
                  <div class="hidden-content">
                    <p style="margin-top:8pt; margin-bottom:7pt; text-align:justify">
                      <font style="color:navy">10:15-10:27a</font> --- Communicating Unexpectedness for Out-of-Distribution Multi-Agent Reinforcement Learning <br>
                      <font style="color:navy">10:27-10:39a</font> --- Balancing Fairness and Efficiency in Traffic Routing via Interpolated Traffic Assignment <br>
                      <font style="color:navy">10:39-10:51a</font> --- Bayesian Soft Actor-Critic: A Directed Acyclic Strategy Graph Based Deep Reinforcement Learning <br>
                      <font style="color:navy">10:51-11:03a</font> --- Learning Communication Policies for Different Follower Behaviors in a Collaborative Reference Game <br>
                      <font style="color:navy">11:03-11:15a</font> --- Developing a Unified Training Framework for Multi-agent Imperfect-information Games: a Case Study of Mahjong and Bridge <br>
                    </p>
                  </div>
                </td>
              </tr>
              <tr>
                <td style="color:navy">11:15a</td>
                <td style="color:navy">Invited Session 2</td>
              </tr>
              <tr>
                <td style="color:maroon">11:15-11:45a</td>
                <td>
                  <div class="collapsible">Giovanni Beltrame (Polytechnique Montreal) - Topic: The role of hierarchy in multi-agent decision making</div>
                  <div class="hidden-content">
                    <p style="margin-top:8pt; margin-bottom:7pt; text-align:justify">
                      <b>
                        <font size="">Abstract:</font>
                      </b>
                        The emerging behaviors of swarms have fascinated scientists and gathered significant interest in the field of robotics. 
			While most robot swarms seen in literature are egalitarian (i.e. all robots have identical roles and capabilities), recent evidence suggest that 
			introducing hierarchy (i.e. some robots act as local decision makers) is essential to successfully deploy robot swarms in a wider range of practical applications. 
			While their abundance in nature hints that hierarchies may have certain advantages over egalitarian swarms, the conditions favoring hierarchies have not been empirically 
			demonstrated. We show evidence that egalitarian swarms perform well in environments that are comparable in size to the collective sensing capability of the swarm, 
			but will eventually fail as environments become larger or more complex. We show how hierarchies extend overall sensing capability of the swarm in a resource-effective manner, 
			succeeding in larger and less structured environments with fewer resources.
                    </p>
                  </div>
                </td>
              </tr>
              <tr>
                <td style="color:maroon">11:45-12:15p</td>
                <td>
                  <div class="collapsible">Michael L. Littman (Brown University) - Topic: Interacting Agents and Safe(r) AI </div>
                  <div class="hidden-content">
                    <p style="margin-top:8pt; margin-bottom:7pt; text-align:justify">
                      <b>
                        <font size="">Abstract:</font>
                      </b>
                        RL plays an important role in creating modern chatbots. This talk explores how some
			of the current shortcomings in chatbot creation can be mitigated by taking a multiagent perspective
			and proposes that considerably more human feedback is needed to create chatbots that would
			generally be seen as "safe" and reliable.
                    </p>
                  </div>
                </td>
              </tr>
              <tr>
                <td>12:15-12:20p</td>
                <td>Q/A and Discussion for Invited Session 2</td>
              </tr>
              <tr>
	        <td style="color:navy">12:20p</td>
	        <td style="color:navy">Break</td>
	      </tr>
              <tr>
                <td style="color:green">2:00p</td>
		<td>
                  <div class="collapsible" style="color:green">Contributed Papers - Poster Session I</div>
                  <div class="hidden-content">
                    <p style="margin-top:8pt; margin-bottom:7pt; text-align:justify">
                      <font style="color:navy">2:00-2:05p</font> --- Cognitive Multi-agent Q-Learning for Cooperation in Competitive Environments <br>
                      <font style="color:navy">2:05-2:10p</font> --- SocialGFs: Learning Social Gradient Fields for Multi-Agent Reinforcement Learning <br>
                      <font style="color:navy">2:10-2:15p</font> --- Innate-Values-driven Reinforcement Learning for Cooperative Multi-Agent Systems <br>
                      <font style="color:navy">2:15-2:20p</font> --- Bridging Agent Dynamics and Population Behaviors: Scalable Learning for Mean Field Games on Graph via Neural Operators <br>
                      <font style="color:navy">2:20-2:25p</font> --- Edge Computing based Human-Robot Cognitive Fusion: A Medical Case Study in the Autism Spectrum Disorder Therapy <br>
		      <font style="color:navy">2:25-2:30p</font> --- Q/A     
                    </p>
                  </div>
                </td>
              </tr>
              <tr>
                <td style="color:navy">2:30p</td>
                <td style="color:navy">Invited Session 3</td>
              </tr>
              <tr>
                <td style="color:maroon">2:30-3:00p</td>
                <td>
                  <div class="collapsible">Sven Koenig (USC) - Topic: Multi-Agent Pathfinding and Its Applications</div>
                  <div class="hidden-content">
                    <p style="margin-top:8pt; margin-bottom:7pt; text-align:justify">
                      <b>
                        <font size="">Abstract:</font>
                      </b>
                        The coordination of robots and other agents is becoming increasingly important for industry. For example, on the order of one thousand robots navigate autonomously 
			in Amazon fulfillment centers to move inventory pods all the way from their storage locations to the picking stations that need the products they store (and vice versa). 
			Optimal and, in some cases, even approximately optimal path planning for these robots is NP-hard, yet one must find high-quality collision-free paths for them in real-time. 
			Algorithms for such multi-agent path-finding problems had been studied in robotics and theoretical computer science for a long time but were insufficient since they are either 
			fast but result in insufficient solution quality or result in good solution quality but are too slow. In this talk, I will discuss different variants of multi-agent path-finding 
			problems and cool ideas for both solving them (in centralized and decentralized ways) and executing the resulting plans robustly. I will also discuss several applications of 
			the technology (funded by NSF and Amazon Robotics), including warehousing, manufacturing, and train scheduling.
                    </p>
                  </div>
                </td>
              </tr>
              <tr>
                <td style="color:maroon">3:00-3:30p</td>
                <td>
                  <div class="collapsible">Christopher Amato (Northeastern University) - Topic: Correcting Some Misconceptions about MARL</div>
                  <div class="hidden-content">
                    <p style="margin-top:8pt; margin-bottom:7pt; text-align:justify">
                      <b>
                        <font size="">Abstract:</font>
                      </b>
                        Multi-agent reinforcement learning (MARL) has exploded in popularity but there is a lack of understanding of when current methods work and what is the best way to learn in multi-agent settings. 
			This talk will include some of the fundamental challenges and misunderstandings of multi-agent reinforcement learning. In particular, it will discuss how 1) centralized critics are not strictly 
			better than decentralized critics in MARL (and can be worse), and 2) state-based critics are unsound and work well only in fully-observable multi-agent problems. Furthermore, it will discuss 
			related methods in value-based MARL. 
                    </p>
                  </div>
                </td>
              </tr>
              <tr>
                <td>3:30-3:35p</td>
                <td>Q/A and Discussion for Invited Session 3</td>
              </tr>
              tr>
              <td style="color:navy">3:35p</td>
              <td style="color:navy">Coffee Break</td>
            </tr
	      <tr>
                <td style="color:green">3:35p</td>
                <td>
                  <div class="collapsible" style="color:green">Contributed Papers - Poster Session II</div>
                  <div class="hidden-content">
                    <p style="margin-top:8pt; margin-bottom:7pt; text-align:justify">
                      <font style="color:navy">3:35-3:40p</font> --- User Models and Bayesian Decision-Making for Human-in-the-Loop Problems <br>
                      <font style="color:navy">3:40-3:45p</font> --- Multi-Robot Cooperative Navigation in Crowds: A Game-Theoretic Learning-Based Model Predictive Control Approach <br>
                      <font style="color:navy">3:45-3:50p</font> --- Exploratory Training: When Annotators Learn About Data <br>
                      <font style="color:navy">3:50-3:55p</font> --- Exploiting Relational Planning and Task-Specific Abstractions for Multiagent Reinforcement Learning in Relational Domains <br>
		      <font style="color:navy">3:55-4:00p</font> --- Q/A     
                    </p>
                  </div>
                </td>
              </tr>
              <tr>
                <td style="color:navy">4:00p</td>
                <td style="color:navy">Invited Session 4</td>
              </tr>
              <tr>
                <td style="color:maroon">4:00-4:30p</td>
                <td>
                  <div class="collapsible">Marco Pavone (Stanford University) - Topic: Artificial Currency Based Government Welfare Programs: From Optimal Design to Audit Games</div>
                  <div class="hidden-content">
                    <p style="margin-top:8pt; margin-bottom:7pt; text-align:justify">
                      <b>
                        <font size="">Abstract:</font>
                      </b>
                        Artificial currencies have grown in prominence in many real-world resource allocation settings, helping alleviate fairness and equity concerns of traditional monetary mechanisms 
			that often favor users with higher incomes. In particular, artificial currencies have gained traction in government welfare programs that support eligible users in the population, 
			e.g., transit benefits programs provide eligible users with subsidized public transit. While such artificial currency based welfare programs are typically well-intentioned and offer 
			immense potential in improving the outcomes for the eligible group of users, the deployment of many such programs in practice is nascent; hence, the efficacy and optimal design of such 
			programs still needs to be formalized. Moreover, such programs are susceptible to several fraud mechanisms, with a notable concern being misreporting fraud, wherein users can misreport 
			their private attributes to gain access to more artificial currency (credits) than they are entitled to. 
			This talk introduces models and methods to study the equilibrium outcomes and the optimal design of such artificial currency based welfare programs to achieve particular societal objectives 
			of an administrator running the benefits program. Moreover, to address the issue of misreporting fraud, we propose a natural audit game, wherein the administrator can audit users at some cost 
			and levy fines against them for misreporting information. Methodologically, we propose a bi-level optimization framework to optimally design artificial currency based welfare mechanisms and 
			develop convex and linear programming approaches to compute the associated equilibrium outcomes. Finally, to highlight the practical viability of our proposed methods, we present case studies 
			in the context of two welfare programs: (i) San Mateo County’s Community Transport Benefits Program, wherein users are provided with travel credits to offset some of their payments for using 
			tolled express lanes on highways, and (ii) Washington D.C.’s federal transit benefits programs that provide subsidized public transit to federal employees.
                    </p>
                  </div>
                </td>
              </tr>
              <tr>
                <td style="color:maroon">4:30-5:10p</td>
                <td>
                  <div class="collapsible">Kevin Leyton-Brown (UBC) - Topic: Modeling Nonstrategic Human Play in Games</div>
                  <div class="hidden-content">
                    <p style="margin-top:8pt; margin-bottom:7pt; text-align:justify">
                      <b>
                        <font size="">Abstract:</font>
                      </b>
                        It is common to assume that players in a game will adopt Nash equilibrium strategies. 
			However, experimental studies have demonstrated that Nash equilibrium is often a poor description of human players' behavior, 
			even in unrepeated normal-form games. Nevertheless, human behavior in such settings is far from random. Drawing on data from real human play, 
			the field of behavioral game theory has developed a variety of models that aim to capture these patterns.
			This talk will survey over a decade of work on this topic, built around the core idea of treating behavioral game theory as a machine learning problem. 
			It will touch on questions such as:
				- Which human biases are most important to model in single-shot game theoretic settings?
				- What loss function should be used to evaluate and fit behavioral models?
				- What can be learned about examining the parameters of these models?
				- How can richer models of nonstrategic play be leveraged to improve models of strategic agents?
				- When does a description of nonstrategic behavior "cross the line" and deserve to be called strategic?
				- How can advances in deep learning be used to yield stronger--albeit harder to interpret--models?
			Finally, there has been much recent excitement about large language models such as GPT-4. 
			Time permitting, the talk will conclude by describing how the economic rationality of such models can be assessed and 
			presenting some initial experimental findings showing the extent to which these models replicate human-like cognitive biases.
                    </p>
                  </div>
                </td>
              </tr>
              <tr>
                <td>5:10-5:15p</td>
                <td>Q/A and Discussion for Invited Session 4</td>
              </tr>
              <tr>
                <td style="color:navy">5:15-5:20p</td>
                <td style="color:navy">Concluding Remarks</td>
              </tr>
            </tbody>
          </table>
        </font>

      </div> -->
	  
  </div>
</section>
	
<section id="work" class="page-section page">
  <div class="container text-center">
    <div class="heading">
      <h2>Contributions</h2>
    </div>

  <h3 style="color:yellow"> Oral Presentation</h3>
  <p style="font-size: 20px;">TBD </p>
	  
<!--       <font size="4" face="Helvetica">
	<br>
        <table width="100%">
          <tbody>
            <tr>
              <td>[#12]</td>
              <td style="color:aqua" align="left">Communicating Unexpectedness for Out-of-Distribution Multi-Agent Reinforcement Learning, <br> <em style="color:thistle" align="left">Min Whoo Lee, Kibeom Kim, Soo Wung Shin, Minsu Lee and Byoung-Tak Zhang</em><br> 
		      <a href="https://drive.google.com/file/d/1N023mB3nIk4ZWKDMQS9foMAlMHB-UPMs/view?usp=drive_link" target="_blank"> [Link to Paper]</a><a href="https://drive.google.com/file/d/12zLGa6pZ2ECdvAgd3f_b6z8BQlbara94/view?usp=sharing" target="_blank"> [Link to Poster]</a>
	      </td>
            </tr>
            <tr>
              <td>[#3]</td>
              <td style="color:aqua" align="left">Balancing Fairness and Efficiency in Traffic Routing via Interpolated Traffic Assignment, <br> <em style="color:thistle" align="left">Devansh Jalota, Kiril Solovey, Matthew Tsao, Stephen Zoepf and Marco Pavone</em><br> 
		      <a href="https://drive.google.com/file/d/1zOoMUDkT3U4_jKgJTgXFWGWgsDHMwoa3/view?usp=sharing" target="_blank"> [Link to Paper]</a><a href="https://drive.google.com/file/d/1VrzrPgXuVTrpudnhxuDrbq4zFfy5e28N/view?usp=sharing" target="_blank"> [Link to Poster]</a>
	      </td>
              </td>
            </tr>
            <tr>
              <td>[#5]</td>
              <td style="color:aqua" align="left">Bayesian Soft Actor-Critic: A Directed Acyclic Strategy Graph Based Deep Reinforcement Learning, <br> <em style="color:thistle" align="left">Qin Yang and Ramviyas Parasuraman</em><br> 
		      <a href="https://drive.google.com/file/d/1XqxA8FK_GnSkUfkqVNn8Lw0lA_-Sviw_/view?usp=sharing" target="_blank"> [Link to Paper]</a><a href="https://drive.google.com/file/d/1FnNPJE-QfRpAnghDkoiXsGxr7jXj_XXo/view?usp=sharing" target="_blank"> [Link to Poster]</a>
	      </td>
              </td>
            </tr>
            <tr>
              <td>[#8]</td>
              <td style="color:aqua" align="left">Learning Communication Policies for Different Follower Behaviors in a Collaborative Reference Game, <br> <em style="color:thistle" align="left">Philipp Sadler, Sherzod Hakimov and David Schlangen</em><br> 
		      <a href="https://drive.google.com/file/d/1h5VrV1OBqrTsrKZLnuZfEadcKm_qHRh0/view?usp=sharing" target="_blank"> [Link to Paper]</a><a href="https://drive.google.com/file/d/1ipaGsVoabwp0oQ8QZcFcNtrwU6wZG8ji/view?usp=sharing" target="_blank"> [Link to Poster]</a>
	      </td>
            </tr>
            <tr>
              <td>[#11]</td>
              <td style="color:aqua" align="left">Developing a Unified Training Framework for Multi-agent Imperfect-information Games: a Case Study of Mahjong and Bridge, <br> <em style="color:thistle" align="left">Zhilei Fan, Wengang Zhou and Houqiang Li</em><br> 
		      <a href="https://drive.google.com/file/d/1RowC9eejyD4esrKovXkIfwtTRTruZdcK/view?usp=sharing" target="_blank"> [Link to Paper]</a><a href="https://drive.google.com/file/d/1fwGY1jcMPhrTymwLGjYYce2itcF0QPTG/view?usp=sharing" target="_blank"> [Link to Poster]</a>
	      </td>
            </tr>
          </tbody>
        </table>
      </font>
	  
      <br> -->
	  
  <h3 style="color:yellow"> Posters</h3>
  <p style="font-size: 20px;">TBD </p>
	  
<!--       <font size="4" face="Helvetica">
	<br>
        <table width="100%">
          <tbody>
            <tr>
              <td>[#14]</td>
              <td style="color:aqua" align="left">Cognitive Multi-agent Q-Learning for Cooperation in Competitive Environments, <br> <em style="color:thistle" align="left">Duy Nhat Phan, Patrick Hytla, Andrew Rice and Thuy Ngoc Nguyen</em><br> 
		      <a href="https://drive.google.com/file/d/19c9z4hcj9mjeMunRk5qTTNc7YrgpWHtW/view?usp=sharing" target="_blank"> [Link to Paper]</a><a href="https://drive.google.com/file/d/1VF2a8gPP6TU9CZ9UMDRwOaqlfd-oU0d3/view?usp=sharing" target="_blank"> [Link to Poster]</a>
	      </td>
            </tr>
            <tr>
              <td>[#4]</td>
              <td style="color:aqua" align="left">SocialGFs: Learning Social Gradient Fields for Multi-Agent Reinforcement Learning, <br> <em style="color:thistle" align="left">Qian Long, Fangwei Zhong, Mingdong Wu, Yizhou Wang and Song-Chun Zhu</em><br> 
		      <a href="https://drive.google.com/file/d/18MTVr8_vGrTrNStbF7GsoluVW-tWzuWQ/view?usp=sharing" target="_blank"> [Link to Paper]</a><a href="https://drive.google.com/file/d/1qZZsLE9ZBE0eITmrH6WcS-aIomOZhCeb/view?usp=sharing" target="_blank"> [Link to Poster]</a>
	      </td>
            </tr>
            <tr>
              <td>[#9]</td>
              <td style="color:aqua" align="left">Bridging Agent Dynamics and Population Behaviors: Scalable Learning for Mean Field Games on Graph via Neural Operators, <br> <em style="color:thistle" align="left">Xu Chen, Shuo Liu and Xuan Di</em><br> 
		      <a href="https://drive.google.com/file/d/1QuYppAmIvIiHaabOd8Vug0XFdDlb5Ddw/view?usp=sharing" target="_blank"> [Link to Paper]</a><a href="https://drive.google.com/file/d/1G9cObDrKtGlXWmgTxnpV7dg_8fInkzC5/view?usp=sharing" target="_blank"> [Link to Poster]</a>
	      </td>
            </tr>
            <tr>
              <td> [#2]</td>
              <td style="color:aqua" align="left">Innate-Values-driven Reinforcement Learning for Cooperative Multi-Agent Systems, <br> <em style="color:thistle" align="left">Qin Yang</em><br> 
		      <a href="https://drive.google.com/file/d/1gDoK_wgDdvAqEgm9aCF-66PKomypiDTo/view?usp=sharing" target="_blank"> [Link to Paper]</a><a href="https://drive.google.com/file/d/19pM6t3aR05ZGcK9vehmyZAA2PLLl8eBj/view?usp=sharing" target="_blank"> [Link to Poster]</a>
	      </td>
            </tr>
            <tr>
              <td>[#7]</td>
              <td style="color:aqua" align="left">Exploratory Training: When Annotators Learn About Data, <br> <em style="color:thistle" align="left">Rajesh Shrestha, Omeed Habibelahian, Arash Termehchy and Paolo Papotti</em><br> 
		      <a href="https://drive.google.com/file/d/12B_eKsHWBUDI_SgahC4BDBFCoZAC02eo/view?usp=sharing" target="_blank"> [Link to Paper]</a>
		      <a href="https://drive.google.com/file/d/1e-C96Pkkoc252mhQSpaTkOYR2CLhr0fl/view?usp=sharing" target="_blank"> [Link to Poster]</a>
	      </td>
            </tr>
            <tr>
              <td>[#20]</td>
              <td style="color:aqua" align="left">User Models and Bayesian Decision-Making for Human-in-the-Loop Problems, <br> <em style="color:thistle" align="left">Sammie Katt and Samuel Kaski</em><br> 
		      <a href="https://drive.google.com/file/d/1-jEG5ZWV_tIop_Fx7VPm8CgGxUUhPgCR/view?usp=sharing" target="_blank"> [Link to Paper]</a>
		      <a href="https://drive.google.com/file/d/1QdNfzF0UAq-zvLYij1XkVJAJebJ_pKXo/view?usp=sharing" target="_blank"> [Link to Poster]</a>
	      </td>
            </tr>
            <tr>
              <td>[#6]</td>
              <td style="color:aqua" align="left">Multi-Robot Cooperative Navigation in Crowds: A Game-Theoretic Learning-Based Model Predictive Control Approach, <br> <em style="color:thistle" align="left">Viet-Anh Le, Vaishnav Tadiparthi, Behdad Chalaki, Hossein Nourkhiz Mahjoub, Jovin D'Sa, Ehsan Moradi-Pari and Andreas A. Malikopoulos</em><br> 
		      <a href="https://drive.google.com/file/d/19vpfVqNGSiavL3bjF6tSA9CoBHNM5aDR/view?usp=sharing" target="_blank"> [Link to Paper]</a><a href="https://drive.google.com/file/d/1AIwHntI4YlnuMYClWXi4e0NLP-uNoRc5/view?usp=sharing" target="_blank"> [Link to Poster]</a>
	      </td>
            </tr>
            <tr>
              <td>[#1]</td>
              <td style="color:aqua" align="left">Edge Computing based Human-Robot Cognitive Fusion: A Medical Case Study in the Autism Spectrum Disorder Therapy, <br> <em style="color:thistle" align="left">Qin Yang</em><br> 
		      <a href="https://drive.google.com/file/d/1yiFgKkKTB8K2nQMlsoUdvV3hVUOlkMzD/view?usp=sharing" target="_blank"> [Link to Paper]</a><a href="https://drive.google.com/file/d/1HiU1HERZV7P58W6ZF9wyU6Xx-TW6X2jU/view?usp=sharing" target="_blank"> [Link to Poster]</a>
	      </td>
            </tr>
		  
            <tr>
              <td>[#17]</td>
              <td style="color:aqua" align="left">Exploiting Relational Planning and Task-Specific Abstractions for Multiagent Reinforcement Learning in Relational Domains, <br> <em style="color:thistle" align="left">Nikhilesh Prabhakar, Ranveer Singh, Prasad Tadepalli and Sriraam Natarajan</em><br> 
		      <a href="https://drive.google.com/file/d/1pEQ3pr0rpW1SKtDjiejWgPtyS4gGbTMu/view?usp=sharing" target="_blank"> [Link to Paper]</a><a href="https://drive.google.com/file/d/1YjPziGMHqBPOjsP9r7jngiSvG18CJJxc/view?usp=sharing" target="_blank"> [Link to Poster]</a>
	      </td>
            </tr>

          </tbody>
        </table>

      </font> -->

  </div>
</section>

<section id="team" class="page-section">
  <div class="container">
    <div class="heading text-center"> 
      <!-- Heading -->
      <h2>Organizing Committee</h2>
    </div>
    <!-- Team Member's Details -->
    <div class="team-content">
      <div class="row">
	<div class="col-md-3 col-sm-6 col-xs-6"> 
          <!-- Team Member -->
          <div class="team-member pDark"> 
            <!-- Image Hover Block -->
            <div class="member-img"> 
              <!-- Image  --> 
              <img class="img-responsive" src="images/qy.jpg" alt="" /> </div>
            <!-- Member Details -->
            <h4><a href="https://rickyang2016.github.io/" target="blank">Qin Yang</a></h4>
            <!-- Designation --> 
            <span class="pos">Assistant Professor, <br /><a href="https://www.is3rlab.org/" target="blank">Intelligent Social Systems and Swarm Robotics Lab (IS<sup>3</sup>R)</a>, <br />Bradley University </span>
          </div>
        </div>
	      
        <div class="col-md-3 col-sm-6 col-xs-6"> 
          <!-- Team Member -->
          <div class="team-member pDark"> 
            <!-- Image Hover Block -->
            <div class="member-img"> 
              <!-- Image  --> 
              <img class="img-responsive" src="images/gb.png" alt="" /> </div>
            <!-- Member Details -->
            <h4><a href="https://www.polymtl.ca/expertises/en/beltrame-giovanni" target="blank">Giovanni Beltrame</a></h4>
            <!-- Designation --> 
            <span class="pos">Professor, <br /><a href="https://mistlab.ca/" target="blank">Making Innovative Space Technology Lab</a>, <br />Polytechnique Montreal</span>
          </div>
        </div>

	<div class="col-md-3 col-sm-6 col-xs-6"> 
          <!-- Team Member -->
          <div class="team-member pDark"> 
            <!-- Image Hover Block -->
            <div class="member-img"> 
              <!-- Image  --> 
              <img class="img-responsive" src="images/aq.png" alt="" /> </div>
            <!-- Member Details -->
            <h4><a href="https://rlab.cs.dartmouth.edu/albertoq/" target="blank">Alberto Quattrini Li</a></h4>
            <!-- Designation --> 
            <span class="pos">Associate Professor, <br /><a href="https://rlab.cs.dartmouth.edu/home/" target="blank">Reality and Robotics Lab</a>, <br />Dartmouth College</span>
          </div>
        </div>
	      
        <div class="col-md-3 col-sm-6 col-xs-6"> 
          <!-- Team Member -->
          <div class="team-member pDark"> 
            <!-- Image Hover Block -->
            <div class="member-img"> 
              <!-- Image  --> 
              <img class="img-responsive" src="images/ca.png" alt="" /> </div>
            <!-- Member Details -->
            <h4><a href="https://www.khoury.northeastern.edu/home/camato/" target="blank">Christopher Amato</a></h4>
            <!-- Designation --> 
            <span class="pos">Associate Professor, <br /><a href="https://llpr.ccs.neu.edu/" target="blank">Lab for Learning and Planning in Robotics</a>, <br />Northeastern University</span>
          </div>
        </div>
	
      </div>     
    </div>
  </div>
  <!--/.container--> 
</section>
	
<section id="contactUs" class="contact-parlex">
  <div class="parlex-back">
    <div class="container">
      <div class="row">
        <div class="heading text-center"> 
          <!-- Heading -->
          <h2>Submission</h2>
	</div>
	  <p style="font-size: 20px;" align="left">Submissions can contain relevant work in all possible stages, including those recently published work, is under submission elsewhere, 
	     was only recently finished, or is still ongoing. Authors of papers published or under submission elsewhere are encouraged to submit these papers or short versions (including abstracts) 
	     to the workshop, educating other researchers about their work, as long as resubmissions are clearly labeled to avoid copyright violations.</p>
          <p style="font-size: 20px;" align="left">We welcome contributions of both short (2-4 pages) and long papers (6-8 pages) related to our stated vision in the <a href="https://aaai.org/conference/aaai/aaai-25/workshops-call/" target="blank">AAAI 2025 proceedings format</a>. 
		  Position papers and surveys are also welcome. The contributions will be non-archival but will be hosted on our workshop website. All contributions will be peer reviewed (single-blind). </p>
	  <p style="font-size: 20px;" align="left">Workshop paper submission deadline: 22 November 2024, 11:59 pm Pacific Time.</p>
	  <p style="font-size: 20px;" align="left">Notification to authors: 21 December 2024.</p>
	  <p style="font-size: 20px;" align="left">Contributions are to be submitted to <a href="https://easychair.org/conferences/?conf=aaai2025cmasdlworksh" target="blank">https://easychair.org/conferences/?conf=aaai2025cmasdlworksh</a>.</p>
	  <p style="font-size: 20px;" align="left">Acceptance papers will be made publicly available on the workshop website. These non-archival papers and their corresponding posters will also remain available on this website after the workshop. The authors will retain copyright of their papers.</p>
	  <p style="font-size: 20px;" align="left">Please contact <a href="is3rlab@gmail.com" target="blank">is3rlab@gmail.com</a> with any questions.</p>
      </div>
    </div>
    <!--/.container--> 
  </div>
</section>

<section id="pastEvents" class="page-section">
  <div class="container">
    <div class="heading text-center"> 
      <!-- Heading -->
      <h2>Past Events</h2>
    </div>
    <!-- Team Member's Details -->
      <p style="font-size: 20px;" align="left">The first workshop:  <a href="https://www.is3rlab.org/aaai24-cmasdl-workshop.github.io/" target="blank">"Cooperative Multi-Agent Systems Decision-Making and Learning: From Individual Needs to Swarm Intelligence"</a> 
      in <a href="https://aaai.org/aaai-24-conference/" target="blank">AAAI 2024</a>.</p>
  <!--/.container--> 
</section>
	
<!--/.page-section-->
<section class="copyright">
  <div class="container">
    <div class="row">
      <div class="col-sm-12 text-center"> Copyright 2024 <strong>IS<sup>3</sup>R Lab</strong> | All Rights Reserved -- by <a href="https://www.is3rlab.org/" target="blank">is3rlab.org</a> </div>
    </div>
    <!-- / .row --> 
  </div>
</section>
<a href="#top" class="topHome"><i class="fa fa-chevron-up fa-2x"></i></a> 

<!--[if lte IE 8]><script src="//ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script><![endif]--> 
<script src="js/modernizr-latest.js"></script> 
<script src="js/jquery-1.8.2.min.js" type="text/javascript"></script> 
<script src="js/bootstrap.min.js" type="text/javascript"></script> 
<script src="js/jquery.isotope.min.js" type="text/javascript"></script> 
<script src="js/fancybox/jquery.fancybox.pack.js" type="text/javascript"></script> 
<script src="js/jquery.nav.js" type="text/javascript"></script> 
<script src="js/jquery.fittext.js"></script> 
<script src="js/waypoints.js"></script> 
<script src="flexslider/jquery.flexslider.js"></script>
<script src="js/custom.js" type="text/javascript"></script> 
<script src="js/owl-carousel/owl.carousel.js"></script>

<script>
    var coll = document.getElementsByClassName("collapsible");

    Array.from(coll).forEach((col, i) => {
      col.addEventListener("click", function () {
        this.classList.toggle("active");
        showHideRow(`hidden-content`, i);
      });
    });

    function showHideRow(className, index) {
      var content = document.getElementsByClassName(className)[index];
      if (content.style.maxHeight) {
        content.style.maxHeight = null;
      } else {
        content.style.maxHeight = content.scrollHeight + "px";
      }
    }
</script>
</body>
</html>
